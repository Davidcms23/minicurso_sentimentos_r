---
title: "Exercícios Práticos"
subtitle: "Minicurso Semana da Estatística - UFRN 2025"
author: "Seu Nome Aqui"
date: "2025"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

# Introdução

Neste roteiro, você será o cientista de dados. Sua missão é escolher uma obra literária disponível em domínio público e aplicar as técnicas de Mineração de Texto e Análise de Sentimentos que aprendemos.

---

## 1. Preparação

Carregue os pacotes necessários.

```{r bibliotecas}
library(tidyverse)
library(tidytext)
library(gutenbergr)
library(syuzhet)
library(wordcloud)
library(RColorBrewer)
```

---

## 2. Coleta de Dados (Sua Escolha)

**Exercício 1:** Escolha um livro!
Você pode encontrar o ID de um livro buscando no site [gutenberg.org](https://www.gutenberg.org/browse/languages/pt).

```{r download}
id_livro <- 2527

livro_bruto <- gutenberg_download(id_livro) 

livro_bruto <- livro_bruto |>
  mutate(linha = row_number())
```

---

## 3. Tokenização

**Exercício 2:** Transforme o texto para o formato "Tidy" (uma palavra por linha).

```{r tokenizacao}
livro_tokenizado <- livro_bruto |>
  unnest_tokens(output = word, input = text)
```

---

## 4. Limpeza

**Exercício 3:** Remova as palavras que não carregam significado (stopwords).
*Atenção:* Se você escolheu um livro em outro idioma (inglês, espanhol), altere o parâmetro da função `stopwords()`.

```{r limpeza}
# Carregando stopwords em português
# stopwords_pt <- data.frame(word = tm::stopwords("portuguese"))

# Removendo
# livro_limpo <- livro_tokenizado |>
#   anti_join(stopwords_pt, by = "word")
data("stop_words")
livro_limpo <- livro_tokenizado |> 
  anti_join(stop_words)
```

---

## 5. Nuvem de Palavras

**Exercício 4:** Gere uma nuvem de palavras para ter uma visão geral do vocabulário da obra escolhida.
*Dica:* Se houver alguma palavra "sujeira" (como "capítulo", "page" ou o nome do autor) aparecendo demais, use o `filter()` para removê-la antes de plotar.

```{r nuvem}
# Contagem
contagem <- livro_limpo |>
  count(word, sort = TRUE) |> 
  filter(word != "charlotte")

# Nuvem
wordcloud(words = contagem$word, 
          freq = contagem$n, 
          min.freq = 10,
          max.words = 60, 
          colors = brewer.pal(8, "Dark2"))
```

---

## 6. Análise Temporal (O Arco Narrativo)

**Exercício 5:** Descubra a "forma emocional" do livro escolhido.
*Importante:* Certifique-se de usar a opção `language` correta ("portuguese", "english", etc.).

```{r temporal}
# calcular sentimento 
sentimentos <- get_sentiment(livro_bruto$text, 
                             method = "syuzhet", 
                             language = "portuguese")

# agrupar por blocos 
livro_arco <- data.frame(linha = 1:length(sentimentos), valor = sentimentos) |>
  mutate(tempo = linha %/% 100) |>
  group_by(tempo) |>
  summarise(saldo = sum(valor))
```

---

## 7. Visualização Final

**Exercício 6:** Plote o gráfico final.

```{r plot}
ggplot(livro_arco, aes(x = tempo, y = saldo)) +
  geom_col(aes(fill = saldo > 0), show.legend = FALSE) +
  geom_smooth(se = FALSE, color = "black") +
  scale_fill_manual(values = c("firebrick", "steelblue")) +
  labs(title = "Arco Narrativo",
       y = "Saldo Emocional",
       x = "Por 100 linhas") +
  theme_minimal()
```

---

## Discussão

Olhe para o gráfico gerado:
1.  O livro termina bem ou mal?
2.  Os "picos" de alegria ou tristeza fazem sentido com a história que você conhece da obra?
3.  O léxico conseguiu captar a essência ou falhou em momentos de ironia/contexto específico?